<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>YOLOv8 Object Detection</title>
    <style>
        video, canvas {
            width: 100%;
            max-width: 600px;
            display: block;
            margin: auto;
        }
        #log {
            position: fixed;
            bottom: 10px;
            left: 10px;
            background: white;
            color: black;
            padding: 10px;
            max-height: 200px;
            overflow-y: auto;
            border: 1px solid black;
        }
    </style>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0"></script>
</head>
<body>
    <h1 align="center">Live Object Detection with YOLOv8. IN DEVELOPMENT</h1>
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas"></canvas>
    <div id="log"></div>
    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const logDiv = document.getElementById('log');
        let session;

        function logMessage(message) {
            setTimeout(() => {
                logDiv.innerHTML += `<p>${message}</p>`;
                logDiv.scrollTop = logDiv.scrollHeight;
                console.log(message);
            }, 500);
        }

        async function setupCamera() {
            try {
                if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                    throw new Error("Browser does not support camera access.");
                }
                
                const constraints = {
                    video: {
                        facingMode: "environment",
                        width: { ideal: 1280 },
                        height: { ideal: 720 }
                    }
                };
                
                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                video.srcObject = stream;
                return new Promise(resolve => {
                    video.onloadedmetadata = () => resolve(video);
                });
            } catch (error) {
                logMessage("Camera access error: " + error.message);
                alert("Camera access error: " + error.message + "\nPlease check your browser permissions.");
            }
        }

        async function loadYOLOv8() {
            try {
                ort.env.wasm.proxy = true;
                ort.env.wasm.numThreads = 1;
                ort.env.wasm.simd = false;

                session = await ort.InferenceSession.create("https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.onnx", {
                    executionProviders: ["cpu"]
                });
                logMessage("YOLOv8 model loaded successfully!");
            } catch (error) {
                logMessage("Error loading YOLOv8 model: " + error);
            }
        }

        async function detectObjects() {
            if (!session) {
                logMessage("YOLOv8 model not loaded. Cannot run inference.");
                return;
            }
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            
            async function detectFrame() {
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                
                logMessage("Running YOLOv8 inference...");
                
                const input = new ort.Tensor("float32", new Float32Array(video.videoWidth * video.videoHeight * 3), [1, 3, video.videoHeight, video.videoWidth]);
                const outputs = await session.run({ images: input });
                
                const boxes = outputs.boxes.data;
                const scores = outputs.scores.data;
                const labels = outputs.labels.data;
                
                for (let i = 0; i < boxes.length; i += 4) {
                    const x = boxes[i];
                    const y = boxes[i + 1];
                    const width = boxes[i + 2] - x;
                    const height = boxes[i + 3] - y;
                    const confidence = scores[i / 4];
                    const label = labels[i / 4];
                    
                    ctx.beginPath();
                    ctx.rect(x, y, width, height);
                    ctx.lineWidth = 2;
                    ctx.strokeStyle = "red";
                    ctx.stroke();
                    
                    ctx.fillStyle = "red";
                    ctx.font = "16px Arial";
                    ctx.fillText(`${label} (${Math.round(confidence * 100)}%)`, x, y - 5);
                }
            }
            detectFrame();
        }

        document.addEventListener("DOMContentLoaded", async () => {
            await setupCamera();
            await loadYOLOv8();
            await detectObjects();
        });
    </script>
</body>
</html>
