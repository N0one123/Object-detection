<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>YOLOv8 Object Detection</title>
    <style>
        video, canvas {
            width: 100%;
            max-width: 600px;
            display: block;
            margin: auto;
        }
        #log {
            position: fixed;
            bottom: 10px;
            left: 10px;
            background: white;
            color: black;
            padding: 10px;
            max-height: 200px;
            overflow-y: auto;
            border: 1px solid black;
        }
    </style>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web"></script>
</head>
<body>
    <h1 align="center">Live Object Detection with YOLOv8</h1>
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas"></canvas>
    <div id="log"></div>
    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const logDiv = document.getElementById('log');
        let session;

        function logMessage(message) {
            logDiv.innerHTML += `<p>${message}</p>`;
            logDiv.scrollTop = logDiv.scrollHeight;
        }

        async function setupCamera() {
            try {
                const constraints = {
                    video: {
                        facingMode: "environment",
                        width: { ideal: 1280 },
                        height: { ideal: 720 }
                    }
                };
                
                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                video.srcObject = stream;
                return new Promise(resolve => {
                    video.onloadedmetadata = () => resolve(video);
                });
            } catch (error) {
                logMessage("Camera access denied: " + error);
                alert("Please enable camera permissions in Safari settings.");
            }
        }

        async function loadYOLO() {
            logMessage("Loading YOLOv8 model...");
            session = await ort.InferenceSession.create("https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.onnx");
            logMessage("YOLOv8 model loaded successfully!");
        }

        async function detectObjects() {
            if (!session) {
                logMessage("Model not loaded yet!");
                return;
            }

            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            
            async function detectFrame() {
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                
                // Convert image to tensor
                const imageTensor = tf.browser.fromPixels(video).toFloat().expandDims(0);
                
                // Run inference
                const results = await session.run({ "images": imageTensor });
                logMessage("Predictions: " + JSON.stringify(results));
                
                requestAnimationFrame(detectFrame);
            }
            detectFrame();
        }

        document.addEventListener("DOMContentLoaded", async () => {
            await setupCamera();
            video.play();
            await loadYOLO();
            setTimeout(detectObjects, 2000);
        });
    </script>
</body>
</html>
